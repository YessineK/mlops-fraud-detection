{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ MLflow Tracking - D√©tection de Fraude\n",
    "\n",
    "**Pipeline:**\n",
    "1. Tracking de 10 mod√®les (4 baseline + 4 tuned + 2 stacking)\n",
    "2. Lecture des r√©sultats avec Pandas\n",
    "3. S√©lection du meilleur mod√®le (ROC-AUC)\n",
    "4. Chargement et utilisation du mod√®le\n",
    "5. Enregistrement dans Model Registry (local)\n",
    "\n",
    "**Dur√©e estim√©e:** 15-20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üì¶ Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports termin√©s\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ML Models\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports termin√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as bassem.benhamed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as bassem.benhamed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"bassem.benhamed/mlops-sep-25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"bassem.benhamed/mlops-sep-25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository bassem.benhamed/mlops-sep-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository bassem.benhamed/mlops-sep-\u001b[1;36m25\u001b[0m initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/18 10:57:10 INFO mlflow.tracking.fluent: Experiment with name 'fraud_detection_simple' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow configur√©\n",
      "üìä Tracking URI: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow\n",
      "üß™ Experiment: fraud_detection_simple\n"
     ]
    }
   ],
   "source": [
    "# Configuration MLflow + DagsHub\n",
    "load_dotenv()\n",
    "\n",
    "DAGSHUB_USERNAME = os.getenv('DAGSHUB_USERNAME', 'bassem.benhamed')\n",
    "DAGSHUB_TOKEN = os.getenv('DAGSHUB_TOKEN', '')\n",
    "DAGSHUB_REPO = os.getenv('DAGSHUB_REPO_NAME', 'mlops-sep-25')\n",
    "\n",
    "MLFLOW_TRACKING_URI = f\"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}.mlflow\"\n",
    "EXPERIMENT_NAME = \"fraud_detection_simple\"\n",
    "\n",
    "# Configuration DagsHub\n",
    "dagshub.init(repo_owner=DAGSHUB_USERNAME, repo_name=DAGSHUB_REPO, mlflow=True)\n",
    "\n",
    "# Configuration MLflow\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# D√©sactiver les features non support√©es par DagsHub\n",
    "os.environ['MLFLOW_ENABLE_LOGGED_MODEL_CREATION'] = 'false'\n",
    "\n",
    "if DAGSHUB_TOKEN:\n",
    "    os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USERNAME\n",
    "    os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN\n",
    "\n",
    "print(\"‚úÖ MLflow configur√©\")\n",
    "print(f\"üìä Tracking URI: {MLFLOW_TRACKING_URI}\")\n",
    "print(f\"üß™ Experiment: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üìÇ Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es\n",
      "   Train: (476392, 21)\n",
      "   Test: (60000, 21)\n"
     ]
    }
   ],
   "source": [
    "# Charger les donn√©es preprocess√©es\n",
    "DATA_PATH = 'processors/preprocessed_data.pkl'\n",
    "\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "print(\"‚úÖ Donn√©es charg√©es\")\n",
    "print(f\"   Train: {X_train.shape}\")\n",
    "print(f\"   Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ü§ñ Fonctions Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions utilitaires d√©finies\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer les m√©triques\n",
    "def calculate_metrics(y_true, y_pred, y_proba):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_proba)\n",
    "    }\n",
    "\n",
    "# Fonction pour logger un mod√®le dans MLflow\n",
    "def log_model_mlflow(model, model_name, stage, metrics, duration, best_params=None):\n",
    "    \"\"\"\n",
    "    Log un mod√®le dans MLflow de mani√®re compatible DagsHub\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_{stage}\"):\n",
    "        # Log params\n",
    "        mlflow.log_param('model_name', model_name)\n",
    "        mlflow.log_param('stage', stage)\n",
    "        mlflow.log_param('n_features', X_train.shape[1])\n",
    "        \n",
    "        # Log best params si disponibles\n",
    "        if best_params:\n",
    "            for k, v in best_params.items():\n",
    "                try:\n",
    "                    mlflow.log_param(f'best_{k}', v)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Log metrics\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            mlflow.log_metric(metric_name, metric_value)\n",
    "        mlflow.log_metric('training_duration', duration)\n",
    "        \n",
    "        # Sauvegarder le mod√®le localement\n",
    "        model_filename = f\"{model_name}_{stage}.pkl\"\n",
    "        with open(model_filename, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        \n",
    "        # Log comme artifact\n",
    "        try:\n",
    "            mlflow.log_artifact(model_filename)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        return run_id, model_filename\n",
    "\n",
    "print(\"‚úÖ Fonctions utilitaires d√©finies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üöÄ Entra√Ænement des Mod√®les Baseline (4 mod√®les)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Entra√Ænement des mod√®les BASELINE...\n",
      "\n",
      "üìä RandomForest... üèÉ View run RandomForest_baseline at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/0dde05d9f3fa47cf95fe40fceadee0e4\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9965 (11.5s)\n",
      "üìä XGBoost... üèÉ View run XGBoost_baseline at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/8b1017c730314e5396548e4d0fc723de\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9985 (0.6s)\n",
      "üìä LightGBM... üèÉ View run LightGBM_baseline at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/1c041d8ddea244cfabdaf21f5bf71927\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9975 (0.9s)\n",
      "üìä CatBoost... üèÉ View run CatBoost_baseline at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/84bb171bde564774a15951ea05f7f7ff\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9953 (1.6s)\n",
      "\n",
      "‚úÖ Baseline termin√©!\n"
     ]
    }
   ],
   "source": [
    "# D√©finir les mod√®les baseline\n",
    "baseline_models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "baseline_results = []\n",
    "trained_models = {}\n",
    "\n",
    "print(\"üöÄ Entra√Ænement des mod√®les BASELINE...\\n\")\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\"üìä {name}...\", end=\" \")\n",
    "    start = datetime.now()\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©triques\n",
    "    metrics = calculate_metrics(y_test, y_pred, y_proba)\n",
    "    duration = (datetime.now() - start).total_seconds()\n",
    "    \n",
    "    # Log dans MLflow\n",
    "    run_id, model_file = log_model_mlflow(model, name, 'baseline', metrics, duration)\n",
    "    \n",
    "    # Stocker\n",
    "    trained_models[f\"{name}_baseline\"] = model\n",
    "    baseline_results.append({\n",
    "        'model': name,\n",
    "        'stage': 'baseline',\n",
    "        'run_id': run_id,\n",
    "        **metrics,\n",
    "        'duration': duration\n",
    "    })\n",
    "    \n",
    "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "print(\"\\n‚úÖ Baseline termin√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üîç Fine-Tuning (4 mod√®les avec n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Fine-Tuning (5 iterations √ó 3 folds)...\n",
      "\n",
      "üìä RandomForest... üèÉ View run RandomForest_tuned at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/10db3e4728074ef69c95dfe337948944\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9956 (187.8s)\n",
      "üìä XGBoost... üèÉ View run XGBoost_tuned at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/c6fb2ba251e143c89585247901fd045a\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9986 (6.3s)\n",
      "üìä LightGBM... üèÉ View run LightGBM_tuned at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/77228da868a7451581de1b3b930c38e2\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9987 (27.4s)\n",
      "üìä CatBoost... üèÉ View run CatBoost_tuned at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/c1520db443014c949f34103c49f38364\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9971 (25.7s)\n",
      "\n",
      "‚úÖ Fine-tuning termin√©!\n"
     ]
    }
   ],
   "source": [
    "# Grilles de recherche simplifi√©es\n",
    "param_distributions = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': randint(100, 300),\n",
    "        'max_depth': randint(10, 25)\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': randint(100, 300),\n",
    "        'max_depth': randint(3, 8),\n",
    "        'learning_rate': uniform(0.01, 0.2)\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': randint(100, 300),\n",
    "        'max_depth': randint(3, 8),\n",
    "        'learning_rate': uniform(0.01, 0.2)\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': randint(100, 300),\n",
    "        'depth': randint(4, 8),\n",
    "        'learning_rate': uniform(0.01, 0.2)\n",
    "    }\n",
    "}\n",
    "\n",
    "tuned_results = []\n",
    "N_ITER = 5  # Nombre d'it√©rations\n",
    "CV_FOLDS = 3\n",
    "\n",
    "print(f\"üîç Fine-Tuning ({N_ITER} iterations √ó {CV_FOLDS} folds)...\\n\")\n",
    "\n",
    "for name, base_model in baseline_models.items():\n",
    "    print(f\"üìä {name}...\", end=\" \")\n",
    "    start = datetime.now()\n",
    "    \n",
    "    # RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_distributions[name],\n",
    "        n_iter=N_ITER,\n",
    "        cv=CV_FOLDS,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©triques\n",
    "    metrics = calculate_metrics(y_test, y_pred, y_proba)\n",
    "    duration = (datetime.now() - start).total_seconds()\n",
    "    \n",
    "    # Log dans MLflow\n",
    "    run_id, model_file = log_model_mlflow(\n",
    "        best_model, name, 'tuned', metrics, duration, search.best_params_\n",
    "    )\n",
    "    \n",
    "    # Stocker\n",
    "    trained_models[f\"{name}_tuned\"] = best_model\n",
    "    tuned_results.append({\n",
    "        'model': name,\n",
    "        'stage': 'tuned',\n",
    "        'run_id': run_id,\n",
    "        **metrics,\n",
    "        'duration': duration\n",
    "    })\n",
    "    \n",
    "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "print(\"\\n‚úÖ Fine-tuning termin√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üéØ Stacking Ensembles (2 mod√®les)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Stacking (LogReg)... üèÉ View run Stacking_LR_ensemble at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/aec55d71e20444a9b36e381812d1ad3e\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9982 (88.5s)\n",
      "üìä Voting (Soft)... üèÉ View run Voting_Soft_ensemble at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1/runs/c92a3cb4838a43018bde82589bb8121f\n",
      "üß™ View experiment at: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow/#/experiments/1\n",
      "ROC-AUC: 0.9983 (17.4s)\n",
      "\n",
      "‚úÖ Ensembles termin√©s!\n"
     ]
    }
   ],
   "source": [
    "# Prendre les meilleurs mod√®les tun√©s pour le stacking\n",
    "estimators = [\n",
    "    ('rf', trained_models['RandomForest_tuned']),\n",
    "    ('xgb', trained_models['XGBoost_tuned']),\n",
    "    ('lgbm', trained_models['LightGBM_tuned']),\n",
    "    ('cat', trained_models['CatBoost_tuned'])\n",
    "]\n",
    "\n",
    "ensemble_results = []\n",
    "\n",
    "# 1. Stacking avec Logistic Regression\n",
    "print(\"üìä Stacking (LogReg)...\", end=\" \")\n",
    "start = datetime.now()\n",
    "\n",
    "stacking_lr = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_lr.fit(X_train, y_train)\n",
    "y_pred = stacking_lr.predict(X_test)\n",
    "y_proba = stacking_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics_stack_lr = calculate_metrics(y_test, y_pred, y_proba)\n",
    "duration = (datetime.now() - start).total_seconds()\n",
    "\n",
    "run_id_lr, _ = log_model_mlflow(stacking_lr, 'Stacking_LR', 'ensemble', metrics_stack_lr, duration)\n",
    "trained_models['Stacking_LR'] = stacking_lr\n",
    "ensemble_results.append({\n",
    "    'model': 'Stacking_LR',\n",
    "    'stage': 'ensemble',\n",
    "    'run_id': run_id_lr,\n",
    "    **metrics_stack_lr,\n",
    "    'duration': duration\n",
    "})\n",
    "\n",
    "print(f\"ROC-AUC: {metrics_stack_lr['roc_auc']:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "# 2. Voting Classifier (soft voting)\n",
    "print(\"üìä Voting (Soft)...\", end=\" \")\n",
    "start = datetime.now()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "y_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics_voting = calculate_metrics(y_test, y_pred, y_proba)\n",
    "duration = (datetime.now() - start).total_seconds()\n",
    "\n",
    "run_id_vote, _ = log_model_mlflow(voting_clf, 'Voting_Soft', 'ensemble', metrics_voting, duration)\n",
    "trained_models['Voting_Soft'] = voting_clf\n",
    "ensemble_results.append({\n",
    "    'model': 'Voting_Soft',\n",
    "    'stage': 'ensemble',\n",
    "    'run_id': run_id_vote,\n",
    "    **metrics_voting,\n",
    "    'duration': duration\n",
    "})\n",
    "\n",
    "print(f\"ROC-AUC: {metrics_voting['roc_auc']:.4f} ({duration:.1f}s)\")\n",
    "\n",
    "print(\"\\n‚úÖ Ensembles termin√©s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üìä Lecture des R√©sultats avec Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä R√©sultats de tous les mod√®les:\n",
      "\n",
      "       model    stage  roc_auc  f1_score   duration\n",
      "RandomForest baseline 0.996511  0.849515  11.458338\n",
      "     XGBoost baseline 0.998453  0.904977   0.585161\n",
      "    LightGBM baseline 0.997478  0.834547   0.888220\n",
      "    CatBoost baseline 0.995347  0.851852   1.573516\n",
      "RandomForest    tuned 0.995562  0.821223 187.815330\n",
      "     XGBoost    tuned 0.998600  0.878587   6.315687\n",
      "    LightGBM    tuned 0.998706  0.888639  27.393214\n",
      "    CatBoost    tuned 0.997095  0.872027  25.669021\n",
      " Stacking_LR ensemble 0.998184  0.881279  88.450149\n",
      " Voting_Soft ensemble 0.998297  0.885097  17.367026\n",
      "\n",
      "üèÜ Top 5 mod√®les (ROC-AUC):\n",
      "\n",
      "      model    stage  roc_auc  f1_score\n",
      "   LightGBM    tuned 0.998706  0.888639\n",
      "    XGBoost    tuned 0.998600  0.878587\n",
      "    XGBoost baseline 0.998453  0.904977\n",
      "Voting_Soft ensemble 0.998297  0.885097\n",
      "Stacking_LR ensemble 0.998184  0.881279\n"
     ]
    }
   ],
   "source": [
    "# Combiner tous les r√©sultats\n",
    "all_results = baseline_results + tuned_results + ensemble_results\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"üìä R√©sultats de tous les mod√®les:\\n\")\n",
    "print(df_results[['model', 'stage', 'roc_auc', 'f1_score', 'duration']].to_string(index=False))\n",
    "\n",
    "# Afficher le top 5 par ROC-AUC\n",
    "print(\"\\nüèÜ Top 5 mod√®les (ROC-AUC):\\n\")\n",
    "top5 = df_results.nlargest(5, 'roc_auc')[['model', 'stage', 'roc_auc', 'f1_score']]\n",
    "print(top5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Lecture depuis MLflow...\n",
      "\n",
      "                             run_id params.model_name params.stage  \\\n",
      "0  77228da868a7451581de1b3b930c38e2          LightGBM        tuned   \n",
      "1  c6fb2ba251e143c89585247901fd045a           XGBoost        tuned   \n",
      "2  8b1017c730314e5396548e4d0fc723de           XGBoost     baseline   \n",
      "3  c92a3cb4838a43018bde82589bb8121f       Voting_Soft     ensemble   \n",
      "4  aec55d71e20444a9b36e381812d1ad3e       Stacking_LR     ensemble   \n",
      "5  1c041d8ddea244cfabdaf21f5bf71927          LightGBM     baseline   \n",
      "6  c1520db443014c949f34103c49f38364          CatBoost        tuned   \n",
      "7  0dde05d9f3fa47cf95fe40fceadee0e4      RandomForest     baseline   \n",
      "8  10db3e4728074ef69c95dfe337948944      RandomForest        tuned   \n",
      "9  84bb171bde564774a15951ea05f7f7ff          CatBoost     baseline   \n",
      "\n",
      "   metrics.roc_auc  metrics.f1_score  metrics.training_duration  \n",
      "0         0.998706          0.888639                  27.393214  \n",
      "1         0.998600          0.878587                   6.315687  \n",
      "2         0.998453          0.904977                   0.585161  \n",
      "3         0.998297          0.885097                  17.367026  \n",
      "4         0.998184          0.881279                  88.450149  \n",
      "5         0.997478          0.834547                   0.888220  \n",
      "6         0.997095          0.872027                  25.669021  \n",
      "7         0.996511          0.849515                  11.458338  \n",
      "8         0.995562          0.821223                 187.815330  \n",
      "9         0.995347          0.851852                   1.573516  \n",
      "\n",
      "‚úÖ 10 runs trouv√©es dans MLflow\n"
     ]
    }
   ],
   "source": [
    "# Lire depuis MLflow directement\n",
    "print(\"\\nüì• Lecture depuis MLflow...\\n\")\n",
    "\n",
    "# Obtenir l'ID de l'experiment\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Rechercher toutes les runs\n",
    "df_mlflow = mlflow.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"metrics.roc_auc > 0\",\n",
    "    order_by=[\"metrics.roc_auc DESC\"]\n",
    ")\n",
    "\n",
    "# Afficher les colonnes importantes\n",
    "if len(df_mlflow) > 0:\n",
    "    cols_to_show = ['run_id', 'params.model_name', 'params.stage', \n",
    "                    'metrics.roc_auc', 'metrics.f1_score', 'metrics.training_duration']\n",
    "    available_cols = [col for col in cols_to_show if col in df_mlflow.columns]\n",
    "    print(df_mlflow[available_cols].head(10))\n",
    "    print(f\"\\n‚úÖ {len(df_mlflow)} runs trouv√©es dans MLflow\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Aucune run trouv√©e dans MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. üèÜ S√©lection du Meilleur Mod√®le (ROC-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ MEILLEUR MOD√àLE (ROC-AUC)\n",
      "============================================================\n",
      "Mod√®le:    LightGBM\n",
      "Stage:     tuned\n",
      "ROC-AUC:   0.9987\n",
      "F1-Score:  0.8886\n",
      "Precision: 0.9018\n",
      "Recall:    0.8758\n",
      "Run ID:    77228da868a7451581de1b3b930c38e2\n",
      "============================================================\n",
      "\n",
      "‚úÖ Mod√®le charg√© : LGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "# Depuis notre DataFrame local\n",
    "best_idx = df_results['roc_auc'].idxmax()\n",
    "best_row = df_results.loc[best_idx]\n",
    "\n",
    "best_model_name = best_row['model']\n",
    "best_stage = best_row['stage']\n",
    "best_run_id = best_row['run_id']\n",
    "best_roc_auc = best_row['roc_auc']\n",
    "\n",
    "print(\"üèÜ MEILLEUR MOD√àLE (ROC-AUC)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mod√®le:    {best_model_name}\")\n",
    "print(f\"Stage:     {best_stage}\")\n",
    "print(f\"ROC-AUC:   {best_roc_auc:.4f}\")\n",
    "print(f\"F1-Score:  {best_row['f1_score']:.4f}\")\n",
    "print(f\"Precision: {best_row['precision']:.4f}\")\n",
    "print(f\"Recall:    {best_row['recall']:.4f}\")\n",
    "print(f\"Run ID:    {best_run_id}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# R√©cup√©rer le mod√®le\n",
    "best_model_key = f\"{best_model_name}_{best_stage}\" if best_stage != 'ensemble' else best_model_name\n",
    "best_model = trained_models.get(best_model_key)\n",
    "\n",
    "print(f\"\\n‚úÖ Mod√®le charg√© : {type(best_model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. üîÑ Chargement du Mod√®le depuis MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Chargement du mod√®le depuis run_id: 77228da868a7451581de1b3b930c38e2\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df66b31b4b284fdd969242c30b28d59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le charg√© depuis MLflow artifact\n",
      "   Type: LGBMClassifier\n",
      "‚úÖ Mod√®le √©galement disponible localement: LightGBM_tuned.pkl\n"
     ]
    }
   ],
   "source": [
    "# Charger le mod√®le depuis le run_id\n",
    "print(f\"üì• Chargement du mod√®le depuis run_id: {best_run_id}\\n\")\n",
    "\n",
    "# Via artifact (compatible DagsHub)\n",
    "try:\n",
    "    # T√©l√©charger l'artifact\n",
    "    model_filename = f\"{best_model_name}_{best_stage}.pkl\"\n",
    "    artifact_uri = f\"runs:/{best_run_id}/{model_filename}\"\n",
    "    \n",
    "    local_path = mlflow.artifacts.download_artifacts(artifact_uri)\n",
    "    \n",
    "    # Charger avec pickle\n",
    "    with open(local_path, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le charg√© depuis MLflow artifact\")\n",
    "    print(f\"   Type: {type(loaded_model).__name__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur de chargement depuis MLflow: {e}\")\n",
    "    print(f\"   Utilisation du mod√®le en m√©moire √† la place\")\n",
    "    loaded_model = best_model\n",
    "\n",
    "# Alternative: Charger depuis fichier local\n",
    "local_model_file = f\"{best_model_name}_{best_stage}.pkl\"\n",
    "if os.path.exists(local_model_file):\n",
    "    with open(local_model_file, 'rb') as f:\n",
    "        loaded_model_local = pickle.load(f)\n",
    "    print(f\"‚úÖ Mod√®le √©galement disponible localement: {local_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test du mod√®le charg√©...\n",
      "\n",
      "üìä Performances du mod√®le charg√©:\n",
      "   accuracy    : 0.9983\n",
      "   precision   : 0.9018\n",
      "   recall      : 0.8758\n",
      "   f1_score    : 0.8886\n",
      "   roc_auc     : 0.9987\n",
      "\n",
      "üîç Pr√©dictions sur 5 exemples:\n",
      "   Sample 1: Fraud=0, Proba=0.0000\n",
      "   Sample 2: Fraud=0, Proba=0.0018\n",
      "   Sample 3: Fraud=0, Proba=0.0002\n",
      "   Sample 4: Fraud=0, Proba=0.0001\n",
      "   Sample 5: Fraud=0, Proba=0.0005\n",
      "\n",
      "‚úÖ Mod√®le fonctionne correctement!\n"
     ]
    }
   ],
   "source": [
    "# Test du mod√®le charg√©\n",
    "print(\"\\nüß™ Test du mod√®le charg√©...\\n\")\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "y_proba_loaded = loaded_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# M√©triques\n",
    "test_metrics = calculate_metrics(y_test, y_pred_loaded, y_proba_loaded)\n",
    "\n",
    "print(\"üìä Performances du mod√®le charg√©:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"   {metric:12s}: {value:.4f}\")\n",
    "\n",
    "# Test sur quelques exemples\n",
    "print(\"\\nüîç Pr√©dictions sur 5 exemples:\")\n",
    "sample_predictions = loaded_model.predict(X_test[:5])\n",
    "sample_probas = loaded_model.predict_proba(X_test[:5])[:, 1]\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"   Sample {i+1}: Fraud={sample_predictions[i]}, Proba={sample_probas[i]:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Mod√®le fonctionne correctement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. üì¶ Enregistrement dans Model Registry (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Enregistrement dans Model Registry...\n",
      "\n",
      "‚úÖ Mod√®le enregistr√© dans le registry\n",
      "   Nom: Best_Fraud_LightGBM\n",
      "   Version: 1.0.0\n",
      "   Stage: production\n",
      "   Path: model_registry/Best_Fraud_LightGBM/1.0.0/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un Model Registry local\n",
    "MODEL_REGISTRY_DIR = Path(\"model_registry\")\n",
    "MODEL_REGISTRY_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def register_model(model, model_name, version=\"1.0.0\", stage=\"production\"):\n",
    "    \"\"\"\n",
    "    Enregistre un mod√®le dans le registry local\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import shutil\n",
    "    \n",
    "    # Cr√©er la structure\n",
    "    model_dir = MODEL_REGISTRY_DIR / model_name.replace(\" \", \"_\")\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    version_dir = model_dir / version\n",
    "    version_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Sauvegarder le mod√®le\n",
    "    model_path = version_dir / \"model.pkl\"\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # M√©tadonn√©es\n",
    "    metadata = {\n",
    "        \"model_name\": model_name,\n",
    "        \"version\": version,\n",
    "        \"stage\": stage,\n",
    "        \"registered_at\": datetime.now().isoformat(),\n",
    "        \"metrics\": test_metrics,\n",
    "        \"run_id\": best_run_id\n",
    "    }\n",
    "    \n",
    "    with open(version_dir / \"metadata.json\", 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # Lien production\n",
    "    if stage == \"production\":\n",
    "        prod_path = model_dir / \"production.pkl\"\n",
    "        shutil.copy(model_path, prod_path)\n",
    "    \n",
    "    return str(model_path)\n",
    "\n",
    "# Enregistrer le meilleur mod√®le\n",
    "print(\"üì¶ Enregistrement dans Model Registry...\\n\")\n",
    "\n",
    "registry_name = f\"Best_Fraud_{best_model_name}\"\n",
    "model_path = register_model(\n",
    "    model=loaded_model,\n",
    "    model_name=registry_name,\n",
    "    version=\"1.0.0\",\n",
    "    stage=\"production\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Mod√®le enregistr√© dans le registry\")\n",
    "print(f\"   Nom: {registry_name}\")\n",
    "print(f\"   Version: 1.0.0\")\n",
    "print(f\"   Stage: production\")\n",
    "print(f\"   Path: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Test de chargement depuis le registry...\n",
      "\n",
      "‚úÖ Mod√®le charg√© depuis le registry\n",
      "   Nom: Best_Fraud_LightGBM\n",
      "   Version: 1.0.0\n",
      "   ROC-AUC: 0.9987\n",
      "\n",
      "üß™ Test de pr√©diction: [0 0 0 0 0]\n",
      "‚úÖ Le mod√®le fonctionne correctement!\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour charger depuis le registry\n",
    "def load_from_registry(model_name, stage=\"production\"):\n",
    "    \"\"\"Charge un mod√®le depuis le registry local\"\"\"\n",
    "    import json\n",
    "    \n",
    "    model_dir = MODEL_REGISTRY_DIR / model_name.replace(\" \", \"_\")\n",
    "    model_path = model_dir / f\"{stage}.pkl\"\n",
    "    \n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # Charger les m√©tadonn√©es\n",
    "    versions = [d for d in model_dir.iterdir() if d.is_dir()]\n",
    "    if versions:\n",
    "        latest_version = sorted(versions)[-1]\n",
    "        with open(latest_version / \"metadata.json\", 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "    \n",
    "    return model, metadata\n",
    "\n",
    "# Test du chargement\n",
    "print(\"\\nüîÑ Test de chargement depuis le registry...\\n\")\n",
    "\n",
    "loaded_from_registry, metadata = load_from_registry(registry_name, stage=\"production\")\n",
    "\n",
    "print(f\"‚úÖ Mod√®le charg√© depuis le registry\")\n",
    "print(f\"   Nom: {metadata.get('model_name', 'N/A')}\")\n",
    "print(f\"   Version: {metadata.get('version', 'N/A')}\")\n",
    "print(f\"   ROC-AUC: {metadata.get('metrics', {}).get('roc_auc', 0):.4f}\")\n",
    "\n",
    "# Test de pr√©diction\n",
    "test_pred = loaded_from_registry.predict(X_test[:5])\n",
    "print(f\"\\nüß™ Test de pr√©diction: {test_pred}\")\n",
    "print(\"‚úÖ Le mod√®le fonctionne correctement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. üìä R√©sum√© Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéâ R√âSUM√â FINAL - MLflow Tracking\n",
      "================================================================================\n",
      "\n",
      "üìä Mod√®les entra√Æn√©s:\n",
      "   ‚Ä¢ Baseline:  4 mod√®les\n",
      "   ‚Ä¢ Tuned:     4 mod√®les (n_iter=5)\n",
      "   ‚Ä¢ Ensemble:  2 mod√®les (Stacking + Voting)\n",
      "   ‚Ä¢ TOTAL:     10 mod√®les\n",
      "\n",
      "üèÜ Meilleur mod√®le:\n",
      "   ‚Ä¢ Nom:       LightGBM\n",
      "   ‚Ä¢ Stage:     tuned\n",
      "   ‚Ä¢ ROC-AUC:   0.9987\n",
      "   ‚Ä¢ F1-Score:  0.8886\n",
      "\n",
      "üîó MLflow:\n",
      "   ‚Ä¢ Tracking URI: https://dagshub.com/bassem.benhamed/mlops-sep-25.mlflow\n",
      "   ‚Ä¢ Experiment:   fraud_detection_simple\n",
      "   ‚Ä¢ Runs totales: 10\n",
      "\n",
      "üì¶ Model Registry:\n",
      "   ‚Ä¢ Nom:     Best_Fraud_LightGBM\n",
      "   ‚Ä¢ Version: 1.0.0\n",
      "   ‚Ä¢ Stage:   production\n",
      "   ‚Ä¢ Path:    model_registry/Best_Fraud_LightGBM\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Pipeline MLflow termin√© avec succ√®s!\n",
      "================================================================================\n",
      "\n",
      "üí° Prochaines √©tapes:\n",
      "   1. Consultez MLflow UI pour voir toutes les runs\n",
      "   2. Chargez le mod√®le avec: load_from_registry()\n",
      "   3. D√©ployez en production\n",
      "   4. Configurez le monitoring\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ R√âSUM√â FINAL - MLflow Tracking\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Mod√®les entra√Æn√©s:\")\n",
    "print(f\"   ‚Ä¢ Baseline:  4 mod√®les\")\n",
    "print(f\"   ‚Ä¢ Tuned:     4 mod√®les (n_iter={N_ITER})\")\n",
    "print(f\"   ‚Ä¢ Ensemble:  2 mod√®les (Stacking + Voting)\")\n",
    "print(f\"   ‚Ä¢ TOTAL:     10 mod√®les\")\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le:\")\n",
    "print(f\"   ‚Ä¢ Nom:       {best_model_name}\")\n",
    "print(f\"   ‚Ä¢ Stage:     {best_stage}\")\n",
    "print(f\"   ‚Ä¢ ROC-AUC:   {best_roc_auc:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {best_row['f1_score']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîó MLflow:\")\n",
    "print(f\"   ‚Ä¢ Tracking URI: {MLFLOW_TRACKING_URI}\")\n",
    "print(f\"   ‚Ä¢ Experiment:   {EXPERIMENT_NAME}\")\n",
    "print(f\"   ‚Ä¢ Runs totales: {len(df_results)}\")\n",
    "\n",
    "print(f\"\\nüì¶ Model Registry:\")\n",
    "print(f\"   ‚Ä¢ Nom:     {registry_name}\")\n",
    "print(f\"   ‚Ä¢ Version: 1.0.0\")\n",
    "print(f\"   ‚Ä¢ Stage:   production\")\n",
    "print(f\"   ‚Ä¢ Path:    {MODEL_REGISTRY_DIR / registry_name.replace(' ', '_')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Pipeline MLflow termin√© avec succ√®s!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüí° Prochaines √©tapes:\")\n",
    "print(\"   1. Consultez MLflow UI pour voir toutes les runs\")\n",
    "print(\"   2. Chargez le mod√®le avec: load_from_registry()\")\n",
    "print(\"   3. D√©ployez en production\")\n",
    "print(\"   4. Configurez le monitoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
